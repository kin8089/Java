su - root
cd / 
mkdir dfs
chown -R chm:chm /dfs (오너를바꿀때 chown명령어를 쓴다.)
systemctl stop firewalld
systemctl disable firewalld
cd /etc/sysconfig/network-scripts
vi ifcfg-enp0s3
BOOTPROTO=dhcp(dynamic hosts configuration protocol 의 약자) 동적이므로 dhcp를 static으로 바꾼다.
IPADDR=192.168.100.150
NETMASK=255.255.255.0
GATEWAY=192.168.100.1
DNS1=168.126.63.1
추가한다.

vi /etc/hosts 들어가서 안에 있는내용 다지우고
192.168.100.150 master
192.168.100.151 slave1
192.168.100.152 slave2
192.168.100.153 slave3, backup 
추가한다.
위와 같은 방법으로 slave1,2,3도 똑같이

**데이터노드(slave1, slave2, slave3) 설정
- ssh 인증서 사본 저장할 디렉토리 생성, 권한 부여
$ mkdir ~/.ssh
$ ll
$ chmod 700 ~/.ssh
$ ll
**기본 tool 설치
cd /etc/yum.repos.d
vi CentOS-Linux-AppStream.repo
   baseurl=http://mirror 를 baseurl=http:// vault로 바꾼다
vi CentOS-Linux-BaseOs.repo
   baseurl=http://mirror 를 baseurl=http:// vault로 바꾼다
yum install net-tools
yum install rsync
yum install wget

**master창에서
cd /hadoop-3.2.2/etc/hadoop
vi hadoop-env.sh
//54라인
export JAVA_HOME=~/jdk1.8.0_321

vi core-site.xml
<configuration>
   <property>
      <name>fs.defaultFS</name>
      <value>hdfs://master:9000</value>
   </property>
</configuration>


vm - master - 설정 - 네트워크 - 어뎁터에 브리지 (나머지도 통일) 

리부트 - ip addr 로 확인


다른 호스트와 동기화 : master에 있는 jdk , hadoop을 데이터 노드에 동기화
	- rsync-daemon 설치
	- rsync -av ~/aaa

ping slave1 

ctl + c : ping 멈추기

-- jdk 동기화

rsync -av ~/jdk1.8.0_321 slave1:~/jdk1.8.0_321
rsync -av ~/jdk1.8.0_321 slave2:~/jdk1.8.0_321
rsync -av ~/jdk1.8.0_321 slave3:~/jdk1.8.0_321

-- .bashrc 파일 동기화

rsync -av ~/.bashrc slave1:~/.bashrc
rsync -av ~/.bashrc slave2:~/.bashrc
rsync -av ~/.bashrc slave3:~/.bashrc

-- hadoop 동기화

rsync -av ~/hadoop-3.2.2/ slave1:~/hadoop-3.2.2/
rsync -av ~/hadoop-3.2.2/ slave2:~/hadoop-3.2.2/
rsync -av ~/hadoop-3.2.2/ slave3:~/hadoop-3.2.2/


-- Name Node : $HADOOP_HOME/etc/hadoop/hdfs-site.xml 파일 수정
	<property>
		<name>dfs.replication</name>  # 기본 복제수
		<value>2</value>
	</property>
	<property>
		<name>dfs.namenode.name.dir</name> 
		<value>file:///dfs/name</value>
	</property>
	<property>
		<name>dfs.namenode.edits.dir</name> 
		<value>file:///dfs/edits</value>
	</property>
	<property>
		<name>dfs.namenode.secondary.http-address</name>  # 기본 복제수
		<value>backup:9868</value>
	</property>

-- vi mapred.site

	<property>
		<name>mapreduce.framework.name</name>  
		<value>yarn</value>
	</property>


-- vi yarn~
	<property>
		<name>yarn.mapreduce.aux-services</name>  
		<value>mapreduce_shuffle</value>  (셔플 : 정렬)
	</property>


-- vi workers

slave1
slave2
slave3


-- ssh-keygen -t rsa

cd .ssh

cp id_rsa.pub authorized_keys

scp (secure copy)

scp ~/.ssh/id_rsa.pub slave1:~/.ssh/authorized_keys