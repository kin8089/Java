https://app.slack.com/client/T039JE02DDK/D03AB6VCPT2


자료나 소스 저장 시 폴더명이 한글은 피하는게 좋음 (다운로드 or 바탕화면)

-> E 드라이브에 폴더 생성해서 진행



-- conda prompt 에서 가상환경 구축 (파이썬 버전은 3.8로 설치)

conda create -n ml-env python=3.8 



-- 가상환경 실행 

conda activate ml-env



-- 가상환경 종료

conda deactivate


-- 주피터 설치

conda install jupyter



-- 폴더 이동

e: = e 드라이브로 이동

-> 생성한 폴더로 cd



-- 주피터 노트북 실행	** 반드시 가상환경을 실행하고 폴더 이동 후 진행

jupyter notebook




-- 윈도우 터미널 (커스터마이징이 편함)

microsoft store -> Windows Terminal 설치 -> 설정 -> json 파일 열기

-> list ->  문단복붙 -> guid 끝에 4자리 변경 -> 아나콘다 파워셀 -> 속성 -> 대상 복사

"commandline": "%windir%\\System32\\WindowsPowerShell\\v1.0\\powershell.exe -ExecutionPolicy ByPass -NoExit -Command \"& 'C:\\Users\\BIT\\Anaconda3\\shell\\condabin\\conda-hook.ps1' ; conda activate 'C:\\Users\\BIT\\Anaconda3' \"",

\한개 있는거 \\개로 만들어줌 + "" 앞에 \한개 추가 -> 저장 & 윈도우 터미널 저장


icon 변경 -> 원하는 아이콘 주소 복사 -> "icon" : " --- "


https://windowsterminalthemes.dev/ 	윈도우 테마 -> 선택 후 get theme

-> scheme 마지막에 복붙 -> name 가져와서 defaults에 "colorScheme" : "name" 넣기




-- atom (소스코드 편집기) 

설정 -> 시스템 -> 아래 두개 체크

텍스트 파일 생성 -> .json 파일로 변경 -> 우클릭 -> 연결 프로그램 변경

-> json파일은 기본적으로 atom으로 실행



-- 사이킷 - 런 설치 (가상환경)

conda install scikit-learn

 pip install mglearn


-- 붓꽃 품종 데이터셋 불러오기 

from sklearn.datasets import load_iris
iris_dataset = load_iris()


-- 키 값 불러오기

print('iris_datasets key\n', iris_dataset.keys())

-- DESCR의 데이터 불러오기

print(iris_dataset['DESCR'][:230])

-- 품종 데이터 불러오기

print(iris_dataset['target_names'])

-- 특성 데이터 불러오기

print(iris_dataset['feature_names'])

-- 데이터 타입 확인

print(type(iris_dataset['data']))

-- 데이터 쉐잎 확인

print(iris_dataset['data'].shape)

-- 실제 데이터 5개 확인

print(iris_dataset['data'][:5])


-- train_test_split 함수를 이용하여 데이터를 나누기 (훈련데이터 / 테스트데이터)

기본 설정값 : 훈련데이터 75% 테스트 데이터 25% , 순서 고정

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(iris_dataset['data'], iris_dataset['target'])


-- 나눈 데이터 확인

print(x_train.shape)
print(y_train.shape)


-- 필요 라이브러리 불러오기

import pandas as pd
import mglearn
import matplotlib.pyplot as plt


-- 나눈 데이터를 가지고 시각화

iris_dataFrame = pd.DataFrame(x_train, columns=iris_dataset['feature_names'])
pd.plotting.scatter_matrix(iris_dataFrame, c=y_train, figsize=(15,15),
                          marker='o', hist_kwds={'bins':20},s=60,alpha=0.8,
                          cmap=mglearn.cm3)
plt.show()



-- 머신러닝 알고리즘 - k-최근접 이웃 알고리즘(k-NN)

이웃을 1로 설정

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=1)


-- 훈련시키키 ->  .fit()

knn.fit(x_train, y_train)


-- 테스트

import numpy as np

x_new = np.array([[5,2.9,1,0.2]])
print(x_new.shape)


prediction = knn.predict(x_new)
print(prediction)

print("target 이름:", iris_dataset['target_names'][prediction])


-- 예측 

y_pred = knn.predict(x_test)
print(y_pred)


-- 정확도

print("정확도: {:.2f}".format(np.mean(y_pred == y_test)))

print("정확도: {:.2f}".format(np.mean(knn.score(x_test,y_test)))


--------------------------------------------------------------------------------------

분류 : 미리 정의된 가능성 있는 여러 클래스 레비블 중 하나를 예측 

회귀 : 연속적인 숫자를 예측, 출력값의 작은 차이는 문제가 되지 않음


과대적합 : 조건이 너무 많으면 새로운 데이터에 일반화 되기 어려움

과소적합 : 조건이 너무 적으면 정확도가 떨어지고 다양성을 잡아내지 못함


-- 지도 학습 알고리즘

import mglearn
import matplotlib.pyplot as plt

X, y = mglearn.datasets.make_forge()
print(X)
print(y)


-- 시각화 

mglearn.discrete_scatter(X[:,0], X[:,1], y)
plt.legend(["Class ", "Class 1"], loc=4)
plt.xlabel('Frist feature')
plt.ylabel('Second feature')
plt.show()


-- 쉐잎 출력

print("X.shape:", X.shape)



-- wave 데이터셋 사용


X, y = mglearn.datasets.make_wave(n_samples=40)
plt.plot(X,y,'o')
plt.ylim(-3,3)
plt.xlabel('Feature')
plt.ylabel('Target')
plt.show()


-- 암 데이터 불러오기

from sklearn.datasets import load_breast_cancer
cancer = load_breast_cancer()
print(cancer.keys())


-- 암 데이터 쉐잎 출력

print(cancer.data.shape)


-- zip , listcomplition

print(cancer.target_names)

import numpy as np
print("클래스별 샘플 수:\n{}".format({n: v for n, v in zip(cancer.target_names,
				 np.bincount(cancer.target))}))


-- feature enginering

X, x = mglearn.datasets.load_extended_boston()
print("X.shape:", X.shape)


---------------------------------------------------------------------------------

k-NN : k-Nearest Neighbors , 가장 가까운 훈련 데이터 샘플을 최근접 이웃으로 찾아 예측에 사용


mglearn.plots.plot_knn_classification(n_neighbors=1)


overfitting : 테스트와 트레이닝사이의 정확도가 크게 떨어짐

underfitting : 테스트와 트레이닝 정확도가 둘다 떨어짐


-----------------------------------------------------------------------------------------

fit : 학습

score : 평가



jupyter notebook --generate-config 


.container { width: 100% !important;}
div.CodeMirror, dic.output_area pre, div.ouput_wrapper pre{
  font-family: Source Code Pro;
  font-size: 19pt;
  line-height: 110%
}
div#notebook, div.prompt{
    font-family: Source Code Pro;
    font-size: 19pt;
    line-height: 110%;
}


사용자 -> .jupyter -> custom에서 폰트 수정 가능